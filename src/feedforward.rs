//! Constructions related to feed-forward networks

use std::cmp::min;

use num::{Float, one, zero};

use Compute;

/// A feedforward layer
pub struct FeedforwardLayer<F: Float, A: Fn(F) -> F> {
    inputs: usize,
    coeffs: Vec<F>,
    biases: Vec<F>,
    activation: A
}

impl<F: Float, A: Fn(F) -> F> FeedforwardLayer<F, A> {
    /// Creates a new linear feedforward layer with all its weights set
    /// to 1 and its biases set to 0
    pub fn new(inputs: usize, outputs: usize, activation: A) -> FeedforwardLayer<F, A> {
        FeedforwardLayer {
            inputs: inputs,
            coeffs: vec![one(); inputs*outputs],
            biases: vec![zero(); outputs],
            activation: activation
        }
    }

    /// Creates a new linear feedforward layer with all its weights and biases
    /// generated by provided closure (for example a random number generator).
    pub fn new_from<G>(inputs: usize, outputs: usize, activation: A, mut generator: G)
        -> FeedforwardLayer<F, A>
        where G: FnMut() -> F
    {
        FeedforwardLayer {
            inputs: inputs,
            coeffs: (0..inputs*outputs).map(|_| generator()).collect(),
            biases: (0..outputs).map(|_| generator()).collect(),
            activation: activation
        }
    }
}

impl<F: Float, A: Fn(F) -> F> Compute<F> for FeedforwardLayer<F, A> {
    fn compute(&self, input: &[F]) -> Vec<F> {
        let n = self.biases.len();
        let mut out = self.biases.clone();
        for i in 0..min(self.inputs, input.len()) {
            for j in 0..n {
                out[j] = out[j] + self.coeffs[i*n + j] * input[i]
            }
        }
        
        for o in &mut out {
            *o = (self.activation)(*o);
        }

        out
    }
}

#[cfg(test)]
mod tests {
    use Compute;
    use super::FeedforwardLayer;

    fn identity<F>(f: F) -> F { f }

    #[test]
    fn compute() {
        let layer = FeedforwardLayer::new_from(4, 2, identity, || 0.5f32);
        let output = layer.compute(&[1.0, 1.0, 1.0, 1.0]);
        // all weigths and biases are 0.5, output should be 4*0.5 + 0.5 = 2.5
        for o in &output {
            assert!((o - 2.5).abs() < 0.00001);
        }
    }
}