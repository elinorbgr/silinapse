//! Constructions related to feed-forward networks

use std::cmp::min;

use num::{Float, one, zero};

use {Compute, SupervisedTrain};
use training::PerceptronRule;

/// A feedforward layer
pub struct FeedforwardLayer<F: Float, A: Fn(F) -> F> {
    inputs: usize,
    coeffs: Vec<F>,
    biases: Vec<F>,
    activation: A
}

impl<F: Float, A: Fn(F) -> F> FeedforwardLayer<F, A> {
    /// Creates a new linear feedforward layer with all its weights set
    /// to 1 and its biases set to 0
    pub fn new(inputs: usize, outputs: usize, activation: A) -> FeedforwardLayer<F, A> {
        FeedforwardLayer {
            inputs: inputs,
            coeffs: vec![one(); inputs*outputs],
            biases: vec![zero(); outputs],
            activation: activation
        }
    }

    /// Creates a new linear feedforward layer with all its weights and biases
    /// generated by provided closure (for example a random number generator).
    pub fn new_from<G>(inputs: usize, outputs: usize, activation: A, mut generator: G)
        -> FeedforwardLayer<F, A>
        where G: FnMut() -> F
    {
        FeedforwardLayer {
            inputs: inputs,
            coeffs: (0..inputs*outputs).map(|_| generator()).collect(),
            biases: (0..outputs).map(|_| generator()).collect(),
            activation: activation
        }
    }
}

impl<F: Float, A: Fn(F) -> F> Compute<F> for FeedforwardLayer<F, A> {
    fn compute(&self, input: &[F]) -> Vec<F> {
        let mut out = self.biases.clone();
        for j in 0..self.biases.len() {
            for i in 0..min(self.inputs, input.len()) {
                out[j] = out[j] + self.coeffs[j*self.inputs + i] * input[i]
            }
        }
        
        for o in &mut out {
            *o = (self.activation)(*o);
        }

        out
    }

    fn input_size(&self) -> usize {
        self.inputs
    }

    fn output_size(&self) -> usize {
        self.biases.len()
    }
}

impl<F: Float, A: Fn(F) -> F> SupervisedTrain<F, PerceptronRule<F>> for FeedforwardLayer<F, A> {
    fn supervised_train(&mut self, rule: &PerceptronRule<F>, input: &[F], target: &[F]) {
        let out = self.compute(input);
        for j in 0..self.biases.len() {
            let diff = target.get(j).map(|v| *v).unwrap_or(zero()) - out[j];
            for i in 0..min(self.inputs, input.len()) {
                self.coeffs[i + j*self.inputs] =
                    self.coeffs[i + j*self.inputs] + rule.rate * diff * input[i];
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use Compute;
    use activations::identity;
    use super::FeedforwardLayer;

    #[test]
    fn compute() {
        let layer = FeedforwardLayer::new_from(4, 2, identity, || 0.5f32);
        let output = layer.compute(&[1.0, 1.0, 1.0, 1.0]);
        // all weigths and biases are 0.5, output should be 4*0.5 + 0.5 = 2.5
        for o in &output {
            assert!((o - 2.5).abs() < 0.00001);
        }
    }
}